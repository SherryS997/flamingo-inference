{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Inference API on Google Colab\n",
    "\n",
    "This notebook demonstrates how to set up and use the chat inference API on Google Colab. It includes both the server and client code.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required dependencies and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask pyyaml torch transformers\n",
    "\n",
    "# Clone your repository (replace with your actual repo URL)\n",
    "!git clone https://github.com/your-username/your-repo.git\n",
    "!cd your-repo\n",
    "\n",
    "# Download your model checkpoint (replace with actual download command)\n",
    "!wget https://your-model-checkpoint-url.com/chat.pt -O chat.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Code\n",
    "\n",
    "Now, let's define the server code for our chat inference API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from flask import Flask, request, jsonify\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "from src.factory import create_model_and_transforms\n",
    "from data import AudioTextDataProcessor\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global variables\n",
    "model = None\n",
    "text_tokenizer = None\n",
    "DataProcessor = None\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def prepare_tokenizer(model_config):\n",
    "    tokenizer_path = model_config['tokenizer_path']\n",
    "    cache_dir = model_config['cache_dir']\n",
    "    text_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_path,\n",
    "        local_files_only=False,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=cache_dir,\n",
    "    )\n",
    "    text_tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"<audio>\", \"<|endofchunk|>\"]}\n",
    "    )\n",
    "    if text_tokenizer.pad_token is None:\n",
    "        text_tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "    if text_tokenizer.sep_token is None:\n",
    "        text_tokenizer.add_special_tokens({\"sep_token\": \"<SEP>\"})\n",
    "    return text_tokenizer\n",
    "\n",
    "def prepare_model(model_config, clap_config, checkpoint_path, device_id=0):\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    model, _ = create_model_and_transforms(\n",
    "        **model_config,\n",
    "        clap_config=clap_config,\n",
    "        use_local_files=False,\n",
    "        gradient_checkpointing=False,\n",
    "        freeze_lm_embeddings=False,\n",
    "    )\n",
    "    model.eval()\n",
    "    model = model.to(device_id)\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "    model_state_dict = {k.replace(\"module.\", \"\"): v for k, v in model_state_dict.items()}\n",
    "    model.load_state_dict(model_state_dict, False)\n",
    "\n",
    "    return model\n",
    "\n",
    "def inference(model, tokenizer, item, processed_item, inference_kwargs, device_id=0):\n",
    "    filename, audio_clips, audio_embed_mask, input_ids, attention_mask = processed_item\n",
    "    audio_clips = audio_clips.to(device_id, dtype=None, non_blocking=True)\n",
    "    audio_embed_mask = audio_embed_mask.to(device_id, dtype=None, non_blocking=True)\n",
    "    input_ids = input_ids.to(device_id, dtype=None, non_blocking=True).squeeze()\n",
    "\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        audio_x=audio_clips.unsqueeze(0),\n",
    "        audio_x_mask=audio_embed_mask.unsqueeze(0),\n",
    "        lang_x=input_ids.unsqueeze(0),\n",
    "        eos_token_id=eos_token_id,\n",
    "        max_new_tokens=128,\n",
    "        **inference_kwargs,\n",
    "    )\n",
    "\n",
    "    outputs_decoded = [\n",
    "        tokenizer.decode(output).split(tokenizer.sep_token)[-1].replace(tokenizer.eos_token, '').replace(tokenizer.pad_token, '').replace('<|endofchunk|>', '') for output in outputs\n",
    "    ]\n",
    "\n",
    "    return outputs_decoded[0]\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    data = request.json\n",
    "    audio_file = data.get('audio_file')\n",
    "    dialogue = data.get('dialogue', [])\n",
    "    \n",
    "    if not audio_file or not dialogue:\n",
    "        return jsonify({\"error\": \"Missing audio_file or dialogue\"}), 400\n",
    "\n",
    "    item = {\n",
    "        'name': audio_file,\n",
    "        'prefix': \"The task is dialog.\",\n",
    "        'dialogue': dialogue\n",
    "    }\n",
    "\n",
    "    processed_item = DataProcessor.process(item)\n",
    "    \n",
    "    inference_kwargs = {\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"num_return_sequences\": 1\n",
    "    }\n",
    "\n",
    "    response = inference(model, text_tokenizer, item, processed_item, inference_kwargs)\n",
    "    \n",
    "    return jsonify({\"response\": response})\n",
    "\n",
    "# Initialize the model and other components\n",
    "config = load_config('configs/chat.yaml')\n",
    "clap_config = config['clap_config']\n",
    "model_config = config['model_config']\n",
    "\n",
    "set_seed(0)\n",
    "text_tokenizer = prepare_tokenizer(model_config)\n",
    "model = prepare_model(\n",
    "    model_config=model_config, \n",
    "    clap_config=clap_config, \n",
    "    checkpoint_path=\"chat.pt\"\n",
    ")\n",
    "\n",
    "DataProcessor = AudioTextDataProcessor(\n",
    "    data_root='model_ckpts/datasets',\n",
    "    clap_config=clap_config,\n",
    "    tokenizer=text_tokenizer,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "print(\"Server initialized and ready to accept requests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Server\n",
    "\n",
    "Now, let's start the Flask server in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def run_app():\n",
    "    app.run(port=5000)\n",
    "\n",
    "thread = Thread(target=run_app)\n",
    "thread.start()\n",
    "print(\"Server is running in the background.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Code\n",
    "\n",
    "Now that our server is running, let's create a client to interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_audio(audio_file, dialogue):\n",
    "    url = \"http://localhost:5000/chat\"\n",
    "    \n",
    "    payload = {\n",
    "        \"audio_file\": audio_file,\n",
    "        \"dialogue\": dialogue\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"audioset/eval_segments/22khz/Y0bRUkLsttto.wav\"\n",
    "dialogue = [\n",
    "    {\"user\": \"What genre does this music belong to?\"}\n",
    "]\n",
    "\n",
    "response = chat_with_audio(audio_file, dialogue)\n",
    "print(\"API Response:\", response)\n",
    "\n",
    "# Add a follow-up question\n",
    "dialogue.append({\"user\": \"Can you describe the vocals in this track?\"})\n",
    "response = chat_with_audio(audio_file, dialogue)\n",
    "print(\"API Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Chat Session\n",
    "\n",
    "Here's an interactive cell where you can have a multi-turn conversation about an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"audioset/eval_segments/22khz/YXyktNsq4SZU.wav\"\n",
    "dialogue = []\n",
    "\n",
    "print(\"Starting an interactive chat session. Type 'quit' to end the conversation.\")\n",
    "while True:\n",
    "    user_input = input(\"Your question: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    \n",
    "    dialogue.append({\"user\": user_input})\n",
    "    response = chat_with_audio(audio_file, dialogue)\n",
    "    \n",
    "    if response:\n",
    "        print(f\"API Response: {response}\")\n",
    "    else:\n",
    "        print(\"Failed to get a response from the API.\")\n",
    "\n",
    "print(\"Chat session ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "When you're done, run this cell to stop the Flask server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import signal\n",
    "\n",
    "os.kill(os.getpid(), signal.SIGINT)\n",
    "print(\"Server stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
